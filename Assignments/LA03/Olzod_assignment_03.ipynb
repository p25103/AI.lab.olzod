{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "def task1(X):\n",
    "#X = np.array([-4, -2])\n",
    "    W1 = np.array([[2.3, -0.64],[-3, -2]])\n",
    "    B1 = np.array([2, -1])\n",
    "    \n",
    "    A1 = np.dot(X, W1) + B1\n",
    "    Z1 = relu(A1)\n",
    "\n",
    "    W2 = np.array([5, 3])\n",
    "    B2 = np.array([-34])\n",
    "\n",
    "    A2 = np.dot(Z1, W2) + B2\n",
    "    Z2 = relu(A2)\n",
    "\n",
    "    print(\"Input:\", X)\n",
    "    print(\"W1 size:\", W1.shape) \n",
    "    print(\"A1:\", A1)\n",
    "    print(\"Z1:\", Z1)\n",
    "\n",
    "    print(\"A2:\", A2)\n",
    "    print(\"Z2:\", Z2)\n",
    "\n",
    "X = np.array([-4, -2])\n",
    "task1(X)\n",
    "\n",
    "X = np.array([0, -2])\n",
    "task1(X)\n",
    "\n",
    "X = np.array([4, -2])\n",
    "task1(X)\n",
    "\n",
    "X = np.array([0, -3])\n",
    "task1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 1]\n",
      "W1 size: (2, 2)\n",
      "A1: [ 2.5 -1. ]\n",
      "Z1: [0.92414182 0.26894142]\n",
      "A2: [0.05861253]\n",
      "Z2: [0.51464894]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def segmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def task2(X):\n",
    "#X = np.array([-4, -2])\n",
    "    W1 = np.array([[2.5, -1.5],[1, -3]])\n",
    "    B1 = np.array([1.5, 2])\n",
    "    \n",
    "    A1 = np.dot(X, W1) + B1\n",
    "    Z1 = segmoid(A1)\n",
    "\n",
    "    W2 = np.array([1, 0.5])\n",
    "    B2 = np.array([-1])\n",
    "\n",
    "    A2 = np.dot(Z1, W2) + B2\n",
    "    Z2 = segmoid(A2)\n",
    "\n",
    "    print(\"Input:\", X)\n",
    "    print(\"W1 size:\", W1.shape) \n",
    "    print(\"A1:\", A1)\n",
    "    print(\"Z1:\", Z1)\n",
    "\n",
    "    print(\"A2:\", A2)\n",
    "    print(\"Z2:\", Z2)\n",
    "\n",
    "X = np.array([0, 1])\n",
    "task2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Intialized network: {'W1': array([[-2,  2],\n",
      "       [-2,  2]]), 'b1': array([ 3, -1]), 'W2': array([[1],\n",
      "       [1]]), 'b2': array([-1])}\n",
      "input x1, x2 0 0 Output y:  [0]\n",
      "input x1, x2 1 0 Output y:  [1]\n",
      "input x1, x2 0 1 Output y:  [1]\n",
      "input x1, x2 1 1 Output y:  [0]\n",
      "OR Intialized network: {'W1': array([[2],\n",
      "       [2]]), 'b1': array([-1])}\n",
      "input x1, x2 0 0 Output y:  [0]\n",
      "input x1, x2 1 0 Output y:  [1]\n",
      "input x1, x2 0 1 Output y:  [1]\n",
      "input x1, x2 1 1 Output y:  [1]\n",
      "AND Intialized network: {'W1': array([[2],\n",
      "       [2]]), 'b1': array([-3])}\n",
      "input x1, x2 0 0 Output y:  [0]\n",
      "input x1, x2 1 0 Output y:  [0]\n",
      "input x1, x2 0 1 Output y:  [0]\n",
      "input x1, x2 1 1 Output y:  [1]\n",
      "NOT Intialized network: {'W1': array([-2]), 'b1': array([1])}\n",
      "input x1 0 Output y:  [1]\n",
      "input x1 1 Output y:  [0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def segmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def step(x):\n",
    "    return np.array(x>0, dtype=np.int)\n",
    "\n",
    "def sigma(x):\n",
    "    return x\n",
    "\n",
    "def init_xor_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[-2, 2], [-2, 2]])\n",
    "    network['b1'] = np.array([3, -1])\n",
    "    network['W2'] = np.array([[1], [1]])\n",
    "    network['b2'] = np.array([-1])\n",
    "    return network\n",
    "\n",
    "def init_or_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[2], [2]])\n",
    "    network['b1'] = np.array([-1])\n",
    "    return network\n",
    "\n",
    "def init_and_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[2], [2]])\n",
    "    network['b1'] = np.array([-3])\n",
    "    return network\n",
    "\n",
    "def init_not_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([-2])\n",
    "    network['b1'] = np.array([1])\n",
    "    return network\n",
    "\n",
    "def FNN_or_and_not(network, x):\n",
    "    W1 = network['W1']\n",
    "    b1 = network['b1']\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = step(a1)\n",
    "    y = sigma(z1)\n",
    "    return y\n",
    "\n",
    "network = init_xor_network()\n",
    "print(\"XOR Intialized network:\", network)\n",
    "\n",
    "for i in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "    x = np.array([i[0], i[1]])\n",
    "    y = FNN_xor(network, x)\n",
    "    print(\"input x1, x2\", i[0], i[1],  \"Output y: \", y)\n",
    "    \n",
    "network = init_or_network()\n",
    "print(\"OR Intialized network:\", network)\n",
    "\n",
    "for i in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "    x = np.array([i[0], i[1]])\n",
    "    y = FNN_or_and_not(network, x)\n",
    "    print(\"input x1, x2\", i[0], i[1],  \"Output y: \", y)\n",
    "    \n",
    "network = init_and_network()\n",
    "print(\"AND Intialized network:\", network)\n",
    "\n",
    "for i in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
    "    x = np.array([i[0], i[1]])\n",
    "    y = FNN_or_and_not(network, x)\n",
    "    print(\"input x1, x2\", i[0], i[1],  \"Output y: \", y)\n",
    "\n",
    "network = init_not_network()\n",
    "print(\"NOT Intialized network:\", network)\n",
    "\n",
    "for i in [(0), (1)]:\n",
    "    x = i\n",
    "    y = FNN_or_and_not(network, x)\n",
    "    print(\"input x1\", i,  \"Output y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'W1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m./dataset\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_tanh_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m./dataset\u001b[0m in \u001b[0;36mpredict_tanh_softmax\u001b[1;34m(network, x)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_tanh_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'W1'"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import pickle\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    print(\"Downloading \" + file_name + \" ... \")\n",
    "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "    print(\"Done\")\n",
    "\n",
    "def download_mnist():\n",
    "    for v in key_file.values():\n",
    "        _download(v)\n",
    "\n",
    "def _load_label(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def _load_img(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, img_size)\n",
    "    print(\"Done\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "    dataset['train_img'] = _load_img(key_file['train_img'])\n",
    "    dataset['train_label'] = _load_label(key_file['train_label'])\n",
    "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def init_mnist():\n",
    "    download_mnist()\n",
    "    dataset = _convert_numpy()\n",
    "    print(\"Creating pickle file ...\")\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done\")\n",
    "\n",
    "def _change_ont_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "    \n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if not flatten:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_ont_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_ont_hot_label(dataset['test_label'])\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "__file__ = \"./dataset\"\n",
    "dataset_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "save_file = dataset_dir + \"/mnist.pkl\"\n",
    "save_file = \"mnist.pkl\"\n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "img_dim = (1, 28, 28)\n",
    "img_size = 784\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=False, flatten=True)\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "def tanh(X):\n",
    "    #e_x = np.exp(-2 * X)\n",
    "    #return (1 - e_x)/(1 + e_x)\n",
    "    return np.sinh(X)/np.cosh(X)\n",
    "\n",
    "def segmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def swish(X):\n",
    "    return X/(1+np.exp(-X))\n",
    "\n",
    "def softmax(X):\n",
    "    X = X - np.max(X)\n",
    "    return np.exp(X) / np.sum(np.exp(x))\n",
    "\n",
    "def init_network():\n",
    "    #global save_file\n",
    "    with open('sample_weight.pkl', 'rb') as f:\n",
    "    #with open('C:\\Users\\olzod\\sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def predict_sigmoid_softmax(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    z1 = sigmoid(np.dot(x, W1) + b1)\n",
    "    z2 = sigmoid(np.dot(z1, W2) + b2)\n",
    "    y = softmax(np.dot(z2, W3) + b3)\n",
    "    return y\n",
    "\n",
    "def predict_tanh_softmax(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    z1 = tanh(np.dot(x, W1) + b1)\n",
    "    z2 = tanh(np.dot(z1, W2) + b2)\n",
    "    y = softmax(np.dot(z2, W3) + b3)\n",
    "    return y\n",
    "\n",
    "def predict_relu_softmax(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    z1 = relu(np.dot(x, W1) + b1)\n",
    "    z2 = relu(np.dot(z1, W2) + b2)\n",
    "    y = softmax(np.dot(z2, W3) + b3)\n",
    "    return y\n",
    "\n",
    "def predict_swish_softmax(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    z1 = swish(np.dot(x, W1) + b1)\n",
    "    z2 = swish(np.dot(z1, W2) + b2)\n",
    "    y = softmax(np.dot(z2, W3) + b3)\n",
    "    return y\n",
    "\n",
    "#img = x_train[0]\n",
    "#label = t_train[0]\n",
    "#print(label)\n",
    "\n",
    "#print(img.shape)\n",
    "#img = img.reshape(28, 28)\n",
    "#print(img.shape)\n",
    "\n",
    "#img_show(img)\n",
    "\n",
    "x, t = get_data()\n",
    "#network = {}\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict_tanh_softmax(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if (p==t[i]):\n",
    "        accuracy_cnt +=1\n",
    "\n",
    "print(\"Tanh Softmax Accuracy:\", str(float(accuracy_cnt)/len(x)))\n",
    "\n",
    "print(x.shape)\n",
    "print(t.shape)\n",
    "\n",
    "print(network['W1'].shape)\n",
    "print(network['b1'].shape)\n",
    "print(network['W2'].shape)\n",
    "print(network['b2'].shape)\n",
    "print(network['W3'].shape)\n",
    "print(network['b3'].shape)\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict_relu_softmax(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if (p==t[i]):\n",
    "        accuracy_cnt +=1\n",
    "\n",
    "print(\"ReLu Softmax Accuracy:\", str(float(accuracy_cnt)/len(x)))\n",
    "\n",
    "print(x.shape)\n",
    "print(t.shape)\n",
    "\n",
    "print(network['W1'].shape)\n",
    "print(network['b1'].shape)\n",
    "print(network['W2'].shape)\n",
    "print(network['b2'].shape)\n",
    "print(network['W3'].shape)\n",
    "print(network['b3'].shape)\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict_swish_softmax(network, x[i])\n",
    "    p = np.argmax(y)\n",
    "    if (p==t[i]):\n",
    "        accuracy_cnt +=1\n",
    "\n",
    "print(\"Swish Softmax Accuracy:\", str(float(accuracy_cnt)/len(x)))\n",
    "\n",
    "print(x.shape)\n",
    "print(t.shape)\n",
    "\n",
    "print(network['W1'].shape)\n",
    "print(network['b1'].shape)\n",
    "print(network['W2'].shape)\n",
    "print(network['b2'].shape)\n",
    "print(network['W3'].shape)\n",
    "print(network['b3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
